{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile #pip install Pillow==9.4.0\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import glob\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from ImageCrop import ImagePreprocessor\n",
    "from SpotterWrapper import Spotter, PolygonVisualizer\n",
    "from IPython.display import display\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "Image.MAX_IMAGE_PIXELS=None\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Specify filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name folders for raw data and processed data\n",
    "map_data_topfolder = 'raw_maps_20231024'\n",
    "map_strec_topfolder = 'processed/strec'\n",
    "\n",
    "for fp in [map_strec_topfolder]:\n",
    "    if not os.path.isdir(fp):\n",
    "        os.makedirs(fp)\n",
    "\n",
    "# IMPORTANT! Locate spotter directory and detectron weights\n",
    "git_clone_location = 'C:/repo/'\n",
    "spotter_directory = git_clone_location + 'mapkurator-spotter/spotter-v2'\n",
    "model_weights = git_clone_location + 'detectron2-master/detectron2/checkpoint/model_v2_en.pth'\n",
    "spotter_config = spotter_directory + '/configs/PALEJUN/Finetune/Rumsey_Polygon_Finetune.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Crop all jpeg maps in (user defined) map_data_topfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid_scan(img_path, output_dir, save_each_layer=False):\n",
    "    image = Image.open(img_path)\n",
    "    image_preprocessor = ImagePreprocessor(image, overlapping_tolerance=0.3, num_layers=5, min_patch_resolution=512, max_patch_resolution=4096)\n",
    "    image_preprocessor.process()\n",
    "    print(\"preprocessing done\")\n",
    "    spotter = Spotter(spotter_config, model_weights, confidence_thresh=0.8, draw_thresh=0.85)\n",
    "    all_layer_results = []\n",
    "\n",
    "    base_image_batch, base_offset_xs, base_offset_ys = image_preprocessor.get_image_patches(0)\n",
    "    vis = PolygonVisualizer()\n",
    "    vis.canvas_from_patches(base_image_batch, base_offset_xs, base_offset_ys)\n",
    "\n",
    "    for i in range(image_preprocessor.num_layers):\n",
    "        # If you want to save for each layer, uncomment the following line\n",
    "        # image_preprocessor.save_patches(os.path.join(output_dir, f'layer_{i}_patches'), layer=i)\n",
    "\n",
    "        image_batch, offset_xs, offset_ys = image_preprocessor.get_image_patches(i)\n",
    "        spotter.load_batch(image_batch, offset_xs, offset_ys)\n",
    "        results = spotter.inference_batch()\n",
    "        all_layer_results.extend(results)\n",
    "\n",
    "        #all_layer_offset_xs.extend(offset_xs)\n",
    "        #all_layer_offset_ys.extend(offset_ys)\n",
    "\n",
    "        if save_each_layer == True:\n",
    "            vis.draw(results).save(os.path.join(output_dir, f'combined_tagged_{i}.png'))\n",
    "            vis.save_json(results, os.path.join(output_dir, f'combined_tagged_{i}.json'))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    vis.draw(all_layer_results).save(os.path.join(output_dir, f'combined_tagged_all_layers.png'))\n",
    "    vis.save_json(all_layer_results, os.path.join(output_dir, f'combined_tagged_all_layers.json'))\n",
    "\n",
    "# Run crop on all maps\n",
    "for map_data_subfolder in next(os.walk(map_data_topfolder))[1]:\n",
    "    jpeg_list = glob.glob(map_data_topfolder + '/' + map_data_subfolder + '/*.jpeg')\n",
    "    if len(jpeg_list) != 1:\n",
    "        print(map_data_subfolder + \" failed. Please ensure there is exactly 1 file with extension .jpeg in the folder.\")\n",
    "    else:\n",
    "        map_image = jpeg_list[0].split(\"\\\\\")[1]\n",
    "        if map_data_subfolder in ['1846_vandevelde', '1874_saunders', '1845_kiepert']: # '1858_vandevelde', '1874_saunders', '1845_kiepert']: #,,]: #'1858_vandevelde', '1847_tobler', '1845_kiepert'\n",
    "            img_path = map_data_topfolder + '/' + map_data_subfolder + \"/\" + map_image\n",
    "            map_name = os.path.basename(img_path).split('.')[0] # get the map name without extension\n",
    "            output_dir = os.path.join(map_strec_topfolder, map_name)\n",
    "            if not os.path.isdir(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            pyramid_scan(img_path, output_dir, save_each_layer=False)\n",
    "            logging.info('Done cropping %s' %img_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Label Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile\n",
    "import json \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import importlib\n",
    "import Clustering\n",
    "import TextRectify\n",
    "import TextAmalgamate\n",
    "import ExtractHandling\n",
    "import json\n",
    "import pickle\n",
    "import SpotterWrapper\n",
    "import Grouping\n",
    "import BezierSplineMetric\n",
    "import FontSimilarity\n",
    "\n",
    "importlib.reload(SpotterWrapper)\n",
    "importlib.reload(Grouping)\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(TextRectify)\n",
    "importlib.reload(TextAmalgamate)\n",
    "importlib.reload(ExtractHandling)\n",
    "importlib.reload(BezierSplineMetric)\n",
    "importlib.reload(FontSimilarity)\n",
    "\n",
    "\n",
    "map_name_in_strec = 'kiepert_1845'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Subword Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cluster_pre_merge = True\n",
    "\n",
    "with open(f'processed/strec/{map_name_in_strec}/combined_tagged_all_layers.json', 'r', encoding='utf-8') as f:\n",
    "\n",
    "    clustered = Clustering.cluster_polygons(json.load(f))\n",
    "\n",
    "    # visualize clusters\n",
    "    #image = Clustering.visualize_polygons(clustered, 'processed/strec/kiepert_1845/raw.jpeg')\n",
    "    #image.save('processed/strec/kiepert_1845/combined_tagged_all_layers_clustering.png')\n",
    "\n",
    "for label, cluster in clustered.items():\n",
    "    texts = []\n",
    "    scores = []\n",
    "    for polygon in cluster:\n",
    "        texts.append(polygon['text'])\n",
    "        scores.append(polygon['score'])\n",
    "\n",
    "    rectifier = TextRectify.TextRectifier(0.95, 0.5, 10, True, True)\n",
    "\n",
    "    rectifier.feed_data(texts, scores)\n",
    "\n",
    "    rectifier.fit()\n",
    "\n",
    "    rectified, mask = rectifier.get_rectified_text()\n",
    "\n",
    "    if rectified is None:\n",
    "        rectified = max(texts, key=len)\n",
    "\n",
    "    for i in range(len(cluster)):\n",
    "        cluster[i]['text'] = rectified[i]\n",
    "        cluster[i]['keep'] = mask[i]\n",
    "\n",
    "image = Clustering.visualize_polygons(clustered, f'processed/strec/{map_name_in_strec}/raw.jpeg')\n",
    "image.save(f'processed/strec/{map_name_in_strec}/combined_tagged_all_layers_rectified.png')\n",
    "\n",
    "polygon_x = {}\n",
    "polygon_y = {}\n",
    "texts = {}\n",
    "scores = {}\n",
    "i = 0\n",
    "for label, cluster in clustered.items():\n",
    "    for polygon in cluster:\n",
    "        if do_cluster_pre_merge:\n",
    "            if polygon['keep']:\n",
    "                polygon_x[str(i)] = polygon['polygon_x']\n",
    "                polygon_y[str(i)] = polygon['polygon_y']\n",
    "                texts[str(i)] = polygon['text']\n",
    "                scores[str(i)] = polygon['score']\n",
    "                i += 1\n",
    "        else:\n",
    "            polygon_x[str(i)] = polygon['polygon_x']\n",
    "            polygon_y[str(i)] = polygon['polygon_y']\n",
    "            texts[str(i)] = polygon['text']\n",
    "            scores[str(i)] = polygon['score']\n",
    "            i += 1\n",
    "\n",
    "json_data = {'polygon_x': polygon_x, 'polygon_y': polygon_y, 'text': texts, 'score': scores}\n",
    "\n",
    "with open(f'processed/strec/{map_name_in_strec}/combined_tagged_all_layers_rectified_premerge.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Nested Word Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947 labels.\n",
      "875 labels.\n",
      "854 labels.\n",
      "852 labels.\n",
      "851 labels.\n",
      "Amalgamation completed with 851 labels.\n"
     ]
    }
   ],
   "source": [
    "# Amalgamation stage - assumes there exists \"combined_tagged_all_layers_rectified_premerge.json\" in map_name_in_strec processed folder.\n",
    "df = ExtractHandling.prepare_labels_for_amalgamation(map_name_in_strec)\n",
    "df = TextAmalgamate.amalgamate_labels_wrapper(df, 0.75, .5)\n",
    "\n",
    "# Save amalgamated labels\n",
    "with open(f'processed/strec/{map_name_in_strec}/deduplicated_flattened_labels.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Multi-Word Sequence Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_name_in_strec = \"vandevelde_1846\"\n",
    "\n",
    "import pickle\n",
    "df = pickle.load(open('processed/strec/' + map_name_in_strec + '/deduplicated_flattened_labels.pickle', 'rb'))\n",
    "\n",
    "df['polygons'] = df['labels'].apply(lambda x: x[0])\n",
    "df['texts'] = df['labels'].apply(lambda x: x[1])\n",
    "\n",
    "# Uncomment to draw splines later\n",
    "## BezierSplineMetric.draw_splines(map_name_in_strec, polygons, texts, PCA_features, all_splines)\n",
    "\n",
    "# reset index so list-based operations match df index\n",
    "df = df.reset_index(drop=True).copy()\n",
    "\n",
    "# pca for principal directions\n",
    "df['PCA_features'] = Grouping.calc_PCA_feats(df['polygons'], do_separation=True, enhance_coords=True)\n",
    "\n",
    "# find neighbors for spline metric consideration\n",
    "df = BezierSplineMetric.calc_neighbours(df, radius_multiplier = 40)\n",
    "\n",
    "# calculate spline metric between identified neighbors\n",
    "df = BezierSplineMetric.spline_metric(df)\n",
    "\n",
    "# Drop PCA_features - no longer needed\n",
    "df.drop('PCA_features', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851 labels.\n",
      "681 labels.\n",
      "556 labels.\n",
      "487 labels.\n",
      "449 labels.\n",
      "434 labels.\n",
      "427 labels.\n",
      "424 labels.\n",
      "422 labels.\n",
      "421 labels.\n",
      "Sequence Recovery completed with 421 labels.\n"
     ]
    }
   ],
   "source": [
    "def combine_labels(label1_row, label2_row):\n",
    "\n",
    "    poly1 = label1_row['labels'][0]\n",
    "    text1 = label1_row['labels'][1]\n",
    "    poly2 = label2_row['labels'][0]\n",
    "    text2 = label2_row['labels'][1]\n",
    "    scores1 = label1_row['scores']\n",
    "    scores2 = label2_row['scores']\n",
    "    neighbours1 = label1_row['neighbours']\n",
    "    neighbours2 = label2_row['neighbours']\n",
    "    if neighbours1 is None:\n",
    "        neighbours1 = []\n",
    "    if neighbours2 is None:\n",
    "        neighbours2 = []\n",
    "\n",
    "    poly_new = poly1.union(poly2)\n",
    "\n",
    "    leftmost_poly = [poly1, poly2].index(min([poly1, poly2], key=lambda shape: shape.bounds[0]))\n",
    "    if leftmost_poly == 0:\n",
    "        text_new = text1 + \" \" + text2\n",
    "    else:\n",
    "        text_new = text2 + \" \" + text1\n",
    "\n",
    "    neighbours_new = list(set(neighbours1 + neighbours2))\n",
    "\n",
    "    scores_new = {key: min(scores1.get(key, float('inf')), scores2.get(key, float('inf'))) for key in set(scores1) | set(scores2)}\n",
    "\n",
    "    return [(poly_new, text_new), poly_new, text_new, neighbours_new, scores_new]\n",
    "\n",
    "def recover_sequence(df, R, to_combine):\n",
    "    for pair in to_combine:\n",
    "        if pair[0] in df.index and pair[1] in df.index:\n",
    "            new_label = combine_labels(df.loc[pair[0]], df.loc[pair[1]])\n",
    "            new_label_index = int(df.index[-1]) + 1\n",
    "            df.loc[new_label_index] = new_label\n",
    "            df = df.drop([pair[0]]).copy()\n",
    "            df = df.drop([pair[1]]).copy()\n",
    "            try:\n",
    "                R.pop(pair[0])\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                R.pop(pair[1])\n",
    "            except:\n",
    "                pass\n",
    "        else: # one of the polygons has already been recovered into a sequence so no combination can no longer occur\n",
    "            pass\n",
    "    return df, R\n",
    "\n",
    "def update_R_matrix(df, font_threshold, bezier_threshold, R = None):\n",
    "    if R == None:\n",
    "        R = {}\n",
    "    to_combine = []\n",
    "    for i, j in combinations(df.index, 2):\n",
    "        if i not in R.keys():\n",
    "            R[i] = {}\n",
    "        if j in R[i].keys():\n",
    "            pass\n",
    "        else:\n",
    "            font_score = 1 #FontSimilarity.font_sim(crop1, crop2)\n",
    "            spline_distance_score = BezierSplineMetric.get_distance_metric(df, i, j, infinitely_large_as=10000000)\n",
    "            R[i][j] = (font_score, spline_distance_score)\n",
    "            if font_score > font_threshold and spline_distance_score < bezier_threshold:\n",
    "                to_combine.append((i,j))\n",
    "    return R, to_combine\n",
    "\n",
    "def sl_sequence_recovery_wrapper(df, font_threshold, bezier_threshold):\n",
    "\n",
    "    pre_seqrec = 0\n",
    "    post_seqrec = len(df)\n",
    "    R = None\n",
    "\n",
    "    while pre_seqrec - post_seqrec != 0:\n",
    "        pre_seqrec = post_seqrec\n",
    "\n",
    "        # map it to comparison matrix, find candidates for sequences\n",
    "        R, to_combine = update_R_matrix(df, font_threshold, bezier_threshold, R)\n",
    "        print(str(pre_seqrec) + \" labels.\")\n",
    "\n",
    "        # recover sequences based on candidates\n",
    "        df, R = recover_sequence(df, R, to_combine)\n",
    "        post_seqrec = len(df)\n",
    "\n",
    "    print(\"Sequence Recovery completed with \" + str(pre_seqrec) + \" labels.\")\n",
    "    return df\n",
    "\n",
    "df = sl_sequence_recovery_wrapper(df, 0, .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to add actual font sim to above iterative process, just a placeholder right now. example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "crop1 = Grouping.polygon_crop(df.iloc[1]['polygons'], Image.open(\"processed/strec/\" + map_name_in_strec + \"/raw.jpeg\"))\n",
    "crop2 = Grouping.polygon_crop(df.iloc[2]['polygons'], Image.open(\"processed/strec/\" + map_name_in_strec + \"/raw.jpeg\"))\n",
    "FontSimilarity.font_sim(crop1, crop2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative process for sequence recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amalgamation stage - assumes there exists \"combined_tagged_all_layers_rectified_premerge.json\" in map_name_in_strec processed folder.\n",
    "df = ?.prepare_labels_for_single_line_sequence_recovery(df)\n",
    "df = ?.single_line_sequence_recovery_wrapper(df, eps11, eps12, eps13)\n",
    "df = ?.multi_line_sequence_recovery_wrapper(df, eps21, eps22, eps23, eps24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import scipy\n",
    "import numpy as np\n",
    "import importlib \n",
    "\n",
    "import Evaluation\n",
    "importlib.reload(Evaluation)\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Isolate crops to be used for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_crop(map_name_in_strec, raw_or_spotter, left_x, right_x, top_y, bottom_y):\n",
    "    if raw_or_spotter == \"raw\":\n",
    "        map_img = Image.open('processed/strec/' + map_name_in_strec + '/raw.jpeg') \n",
    "    elif raw_or_spotter == \"spotter_0\":\n",
    "        map_img = Image.open('processed/strec/' + map_name_in_strec + '/combined_tagged_0.png')\n",
    "    elif raw_or_spotter == \"spotter_1\":\n",
    "        map_img = Image.open('processed/strec/' + map_name_in_strec + '/combined_tagged_1.png')\n",
    "    elif raw_or_spotter == \"spotter_2\":\n",
    "        map_img = Image.open('processed/strec/' + map_name_in_strec + '/combined_tagged_2.png')\n",
    "    elif raw_or_spotter == \"all\":\n",
    "        map_img = Image.open('processed/strec/' + map_name_in_strec + '/combined_tagged_all_layers.png')\n",
    "    elif raw_or_spotter == \"rectified\":\n",
    "        map_img = Image.open('processed/strec/' + map_name_in_strec + '/combined_tagged_all_layers_rectified.png')\n",
    "    width, height = map_img.size\n",
    "    print(\"full map is \" + str(width) + \" pixels wide by \" + str(height) + \" pixels high.\\n displaying crop:\")\n",
    "    display(map_img.crop((left_x, top_y, right_x, bottom_y, )))\n",
    "\n",
    "left_x = 2475\n",
    "right_x = 3550\n",
    "top_y = 4820\n",
    "bottom_y = 5850\n",
    "\n",
    "#visualize_crop(\"kiepert_1845\", \"all\", left_x, right_x, top_y, bottom_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiepert_gt_patch_1 = [2475, 3550, 4820, 5850]\n",
    "saunders_gt_patch_1 = [3150, 4150, 2250, 3250]\n",
    "saunders_gt_patch_2 = [6750, 7750, 2250, 3250]\n",
    "saunders_gt_patch_3 = [5400, 6400, 4500, 5500]\n",
    "saunders_gt_patch_4 = [7650, 8650, 5400, 6400]\n",
    "saunders_gt_patch_5 = [7650, 8650, 3150, 4150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Precision and Recall: IoU after 1:1 Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retaining 49 labels fully inside crop area\n",
      "retaining 43 labels that have alphabetic characters\n",
      "retaining 74 labels fully inside crop area\n",
      "retaining 69 labels that have alphabetic characters\n",
      "retaining 6 labels fully inside crop area\n",
      "retaining 6 labels that have alphabetic characters\n",
      "retaining 13 labels fully inside crop area\n",
      "retaining 11 labels that have alphabetic characters\n",
      "retaining 11 labels fully inside crop area\n",
      "retaining 10 labels that have alphabetic characters\n",
      "retaining 35 labels fully inside crop area\n",
      "retaining 32 labels that have alphabetic characters\n",
      "retaining 47 labels fully inside crop area\n",
      "retaining 46 labels that have alphabetic characters\n",
      "retaining 87 labels fully inside crop area\n",
      "retaining 87 labels that have alphabetic characters\n",
      "retaining 25 labels fully inside crop area\n",
      "retaining 23 labels that have alphabetic characters\n",
      "retaining 65 labels fully inside crop area\n",
      "retaining 60 labels that have alphabetic characters\n",
      "retaining 33 labels fully inside crop area\n",
      "retaining 33 labels that have alphabetic characters\n",
      "retaining 71 labels fully inside crop area\n",
      "retaining 67 labels that have alphabetic characters\n",
      "retaining 49 labels fully inside crop area\n",
      "retaining 43 labels that have alphabetic characters\n",
      "retaining 32 labels fully inside crop area\n",
      "retaining 32 labels that have alphabetic characters\n",
      "retaining 6 labels fully inside crop area\n",
      "retaining 6 labels that have alphabetic characters\n",
      "retaining 7 labels fully inside crop area\n",
      "retaining 6 labels that have alphabetic characters\n",
      "retaining 11 labels fully inside crop area\n",
      "retaining 10 labels that have alphabetic characters\n",
      "retaining 7 labels fully inside crop area\n",
      "retaining 5 labels that have alphabetic characters\n",
      "retaining 47 labels fully inside crop area\n",
      "retaining 46 labels that have alphabetic characters\n",
      "retaining 9 labels fully inside crop area\n",
      "retaining 8 labels that have alphabetic characters\n",
      "retaining 25 labels fully inside crop area\n",
      "retaining 23 labels that have alphabetic characters\n",
      "retaining 0 labels fully inside crop area\n",
      "retaining 33 labels fully inside crop area\n",
      "retaining 33 labels that have alphabetic characters\n",
      "retaining 0 labels fully inside crop area\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "## Patch-level geographic pairings for non-multiline-toponyms against our pyramid pipeline\n",
    "pyramid_detected_kiepert, num_gt_kiepert, pyramid_IoU_pairs_kiepert = Evaluation.geographic_evaluation(\"kiepert_1845\", \"components\", kiepert_gt_patch_1)\n",
    "pyramid_detected_saunders1, num_gt_saunders1, pyramid_IoU_pairs_saunders1 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", saunders_gt_patch_1)\n",
    "pyramid_detected_saunders2, num_gt_saunders2, pyramid_IoU_pairs_saunders2 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", saunders_gt_patch_2)\n",
    "pyramid_detected_saunders3, num_gt_saunders3, pyramid_IoU_pairs_saunders3 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", saunders_gt_patch_3)\n",
    "pyramid_detected_saunders4, num_gt_saunders4, pyramid_IoU_pairs_saunders4 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", saunders_gt_patch_4)\n",
    "pyramid_detected_saunders5, num_gt_saunders5, pyramid_IoU_pairs_saunders5 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", saunders_gt_patch_5)\n",
    "\n",
    "## Aggregating pyramid numbers and pairs to map-level figures\n",
    "num_gt_kiepert = num_gt_kiepert\n",
    "num_gt_saunders = num_gt_saunders1 + num_gt_saunders2 + num_gt_saunders3 + num_gt_saunders4 + num_gt_saunders5\n",
    "pyramid_detected_kiepert = pyramid_detected_kiepert\n",
    "pyramid_detected_saunders = pyramid_detected_saunders1 + pyramid_detected_saunders2 + pyramid_detected_saunders3 + pyramid_detected_saunders4 + pyramid_detected_saunders5\n",
    "pyramid_IoU_pairs_kiepert = pyramid_IoU_pairs_kiepert\n",
    "pyramid_IoU_pairs_saunders = np.concatenate((pyramid_IoU_pairs_saunders1, pyramid_IoU_pairs_saunders2, pyramid_IoU_pairs_saunders3, pyramid_IoU_pairs_saunders4, pyramid_IoU_pairs_saunders5))\n",
    "\n",
    "## Patch-level geographic pairings for non-multiline-toponyms against baseline\n",
    "baseline_detected_kiepert, num_gt_kiepert, baseline_IoU_pairs_kiepert = Evaluation.geographic_evaluation(\"kiepert_1845\", \"components\", [2475, 3550, 4820, 5850], \"combined_tagged_0.json\")\n",
    "baseline_detected_saunders1, num_gt_saunders1, baseline_IoU_pairs_saunders1 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", [3150, 4150, 2250, 3250], \"combined_tagged_0.json\")\n",
    "baseline_detected_saunders2, num_gt_saunders2, baseline_IoU_pairs_saunders2 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", [6750, 7750, 2250, 3250], \"combined_tagged_0.json\")\n",
    "baseline_detected_saunders3, num_gt_saunders3, baseline_IoU_pairs_saunders3 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", [5400, 6400, 4500, 5500], \"combined_tagged_0.json\")\n",
    "baseline_detected_saunders4, num_gt_saunders4, baseline_IoU_pairs_saunders4 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", [7650, 8650, 5400, 6400], \"combined_tagged_0.json\")\n",
    "baseline_detected_saunders5, num_gt_saunders5, baseline_IoU_pairs_saunders5 = Evaluation.geographic_evaluation(\"saunders_1874\", \"components\", [7650, 8650, 3150, 4150], \"combined_tagged_0.json\")\n",
    "\n",
    "## Aggregate baseline numbers and pairs to map-level figures\n",
    "baseline_detected_kiepert = baseline_detected_kiepert\n",
    "baseline_detected_saunders = baseline_detected_saunders1 + baseline_detected_saunders2 + baseline_detected_saunders3 + baseline_detected_saunders4 + baseline_detected_saunders5\n",
    "baseline_IoU_pairs_kiepert = baseline_IoU_pairs_kiepert\n",
    "baseline_IoU_pairs_saunders = np.concatenate((baseline_IoU_pairs_saunders1, baseline_IoU_pairs_saunders2, baseline_IoU_pairs_saunders3, baseline_IoU_pairs_saunders4, baseline_IoU_pairs_saunders5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kiepert baseline\n",
      "\n",
      "Avg of Geographic Precision: 0.19116442583187376\n",
      "Avg of Geographic Recall: 0.14226189829348745\n",
      "Avg of Text Precision: 0.08627091726132564\n",
      "Avg of Text Recall: 0.06420161284563769\n",
      "\n",
      "kiepert pyramid\n",
      "\n",
      "Avg of Geographic Precision: 0.31668587247270935\n",
      "Avg of Geographic Recall: 0.5081703535027197\n",
      "Avg of Text Precision: 0.2951939227107476\n",
      "Avg of Text Recall: 0.47368327132654847\n",
      "\n",
      "saunders baseline\n",
      "\n",
      "Avg of Geographic Precision: 0.06051490020519661\n",
      "Avg of Geographic Recall: 0.00974392460931132\n",
      "Avg of Text Precision: 0.08252460898511729\n",
      "Avg of Text Recall: 0.013287860768790072\n",
      "\n",
      "saunders pyramid\n",
      "\n",
      "Avg of Geographic Precision: 0.21679753988318085\n",
      "Avg of Geographic Recall: 0.4721776927964193\n",
      "Avg of Text Precision: 0.191391017192887\n",
      "Avg of Text Recall: 0.4168431476150166\n"
     ]
    }
   ],
   "source": [
    "# Gimme them numbers :)\n",
    "print(\"\\nkiepert baseline\\n\")\n",
    "Evaluation.prec_rec(baseline_IoU_pairs_kiepert, baseline_detected_kiepert, num_gt_kiepert)\n",
    "print(\"\\nkiepert pyramid\\n\")\n",
    "Evaluation.prec_rec(pyramid_IoU_pairs_kiepert, pyramid_detected_kiepert, num_gt_kiepert)\n",
    "print(\"\\nsaunders baseline\\n\")\n",
    "Evaluation.prec_rec(baseline_IoU_pairs_saunders, baseline_detected_saunders, num_gt_saunders)\n",
    "print(\"\\nsaunders pyramid\\n\")\n",
    "Evaluation.prec_rec(pyramid_IoU_pairs_saunders, pyramid_detected_saunders, num_gt_saunders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
